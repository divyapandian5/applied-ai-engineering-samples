{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ5caKL2Ff2B"
   },
   "source": [
    "# Chatbot with Vertex AI Extensions Code Interpreter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocycMnwJGUii"
   },
   "source": [
    "| | |\n",
    "|----------|-------------|\n",
    "| Authors   | Divya Veerapandian |\n",
    "| Reviewer | Kanchana Patolla |\n",
    "| Last updated | 2024 05 17: Initial release |\n",
    "| |  : Complete draft |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlkJDD0nGUij"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook shows how to use the [Vertex AI Extensions](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview) Google-provided [Code Interpreter Extension](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions.md#code_interpreter_extension) and create a simple Chatbot for the user to be able to upload the CSV and ask questions on top of it\n",
    "\n",
    "In this notebook you will use Code Interpreter to explore data via Chatbot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIBXCGNGfPKL"
   },
   "source": [
    "**If you're already familiar with Google Cloud and the Vertex AI Extensions Code Interpreter Extension**, you can skip reading between here and the \"Create the Data\" section, but make sure to run the code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUXzlvfpn513"
   },
   "source": [
    "## Vertex AI Extensions\n",
    "\n",
    "[Vertex AI Extensions](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview) is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf. You can use pre-built or third-party extensions in Vertex AI Extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3r29fUEFn8JH"
   },
   "source": [
    "## Vertex AI Extensions Code Interpreter Extension\n",
    "\n",
    "The [Code Interpreter](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions.md#code_interpreter_extension) extension provides access to a Python interpreter with a sandboxed, secure execution environment that can be used with any model in the Vertex AI Model Garden. This extension can generate and execute code in response to a user query or workflow. It allows the user or LLM agent to perform various tasks such as data analysis and visualization on new or existing data files.\n",
    "\n",
    "You can use the Code Interpreter extension to:\n",
    "\n",
    "* Generate and execute code.\n",
    "* Perform a wide variety of mathematical calculations.\n",
    "* Sort, filter, select the top results, and otherwise analyze data (including data acquired from other tools and APIs).\n",
    "* Create visualizations, plot charts, draw graphs, shapes, print results, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLf5oGqHn_DH"
   },
   "source": [
    "## Google Cloud Project Setup\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTuXDJ2qn-8W"
   },
   "source": [
    "## Google Cloud Permissions\n",
    "Make sure you have been [granted the following roles](https://cloud.google.com/iam/docs/granting-changing-revoking-access) for the GCP project you'll access from this notebook:\n",
    "* [`roles/aiplatform.user`](https://cloud.google.com/vertex-ai/docs/general/access-control#aiplatform.user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdU-qMmbpR8r"
   },
   "source": [
    "## Install the Google Cloud Vertex AI Python SDK\n",
    "\n",
    "Install the Google Cloud Vertex AI Python SDK, and if you already have the Google Cloud Vertex AI Python SDK installed, upgrade to the latest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHEI7wZMhZPd",
    "outputId": "b7877c1f-1459-463a-9dac-b1c9469b6a4a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.50.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Using cached google_cloud_aiplatform-1.51.0-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.11.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.23.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.13.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.13.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.4)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.8.5)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.6.4)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.15)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.61.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.59.2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.8.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2023.7.22)\n",
      "Using cached google_cloud_aiplatform-1.51.0-py2.py3-none-any.whl (5.0 MB)\n",
      "Installing collected packages: google-cloud-aiplatform\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.50.0\n",
      "    Uninstalling google-cloud-aiplatform-1.50.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.50.0\n",
      "Successfully installed google-cloud-aiplatform-1.51.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "You may need to restart your notebook runtime to use the Vertex AI SDK. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "You may see the restart reported as a crash, but it is working as-intended -- you are merely restarting the runtime.\n",
    "\n",
    "The restart might take a minute or longer. After its restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "52d5d9b1-bec8-45b8-c9c4-ac90fdd119d7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCG23ih_sJr9"
   },
   "source": [
    "If you're using Colab, as long the notebook runtime isn't deleted (even if it restarts) you don't need to re-run the previous cell.\n",
    "\n",
    "If you're running this notebook in your own environment you shouldn't need to run the above pip cell again unless you delete your IPython kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7plalcaLGUik"
   },
   "source": [
    "## Authenticate\n",
    "\n",
    "If you're using Colab, run the code in the next cell. Follow the popups and authenticate with an account that has access to your Google Cloud [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects).\n",
    "\n",
    "If you're running this notebook somewhere besides Colab, make sure your environment has the right Google Cloud access. If that's a new concept to you, consider looking into [Application Default Credentials for your local environment](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev) and [initializing the Google Cloud CLI](https://cloud.google.com/docs/authentication/gcloud). More authentication options are discussed [here](https://cloud.google.com/docs/authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THYfMKWMGUil",
    "outputId": "5d255bb0-a125-4516-ffed-a7b1336040b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colab authentication.\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print('Authenticated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "# Initialize the Google Cloud Vertex AI Python SDK\n",
    "\n",
    "Start here if your Notebook kernel restarts (but isn't deleted), though if it's been a few hours you may need to run the Authentication steps above again.\n",
    "\n",
    "To initialize the SDK, you need to set your Google Cloud project ID and region.\n",
    "\n",
    "If you don't know your project  ID, try the [Google Cloud CLI](https://cloud.google.com/sdk) commands [`gcloud config list`](https://cloud.google.com/sdk/gcloud/reference/config/list) or [`gcloud projects list`](https://cloud.google.com/sdk/gcloud/reference/projects/list). See the support page [Locate the project ID](https://support.google.com/googleapi/answer/7014113) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Set Your Project ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oM1iC_MfAts1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "### Set the Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cg9uNa6rlyWx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fadEmDvz04h"
   },
   "source": [
    "### Import the Vertex AI Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KhnzTqS8iOJC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import extensions\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "import pprint\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from io import StringIO\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIZnIItkxeb-"
   },
   "source": [
    "# Setup and Test the Code Interpreter Extension\n",
    "\n",
    "Code Interpreter is provided by Google, so you can load it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zAMy-Ndinbz",
    "outputId": "f0229d21-31ce-4e5d-ea5c-843b86a20303",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Extension\n",
      "Create Extension backing LRO: projects/1050570861770/locations/us-central1/extensions/8199541993441853440/operations/6237291454465572864\n",
      "Extension created. Resource name: projects/1050570861770/locations/us-central1/extensions/8199541993441853440\n",
      "To use this Extension in another session:\n",
      "extension = vertexai.preview.extensions.Extension('projects/1050570861770/locations/us-central1/extensions/8199541993441853440')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<vertexai.extensions._extensions.Extension object at 0x7f1e4982df00> \n",
       "resource name: projects/1050570861770/locations/us-central1/extensions/8199541993441853440"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension_code_interpreter = extensions.Extension.from_hub(\"code_interpreter\")\n",
    "extension_code_interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqlgusC10Es3"
   },
   "source": [
    "Confirm your Code Interpreter extension is registered:Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAxsJvBh0Es3",
    "outputId": "ce635486-dd34-4060-febe-9504bd7a24cb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: projects/1050570861770/locations/us-central1/extensions/8199541993441853440\n",
      "Display Name: Code Interpreter\n",
      "Description: This extension generates and executes code in the specified language\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", extension_code_interpreter.gca_resource.name)\n",
    "print(\"Display Name:\", extension_code_interpreter.gca_resource.display_name)\n",
    "print(\"Description:\", extension_code_interpreter.gca_resource.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Functions for Code Interpreter Response Formatting required for Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper method to read and encode files.\n",
    "def upload_file_multiple(file_paths):\n",
    "    files = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            encoded_string = base64.b64encode(file.read()).decode()\n",
    "            files.append({\n",
    "                \"name\": file_path.split(\"/\")[-1], \"contents\": encoded_string})\n",
    "    return files\n",
    "\n",
    "def upload_file(file_path):\n",
    "    files = []\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        encoded_string = base64.b64encode(file.read()).decode()\n",
    "        files.append({\n",
    "                \"name\": file_path.split(\"/\")[-1], \"contents\": encoded_string})\n",
    "    return files\n",
    "\n",
    "def get_response(query,files):\n",
    "    response = extension_code_interpreter.execute(\n",
    "    operation_id = \"generate_and_execute\",\n",
    "    operation_params = {\"query\": QUERY, \"files\": FILES},\n",
    "    )\n",
    "    result,resultdataframe = format_response(response)\n",
    "    return result,resultdataframe \n",
    "\n",
    "def format_response(response):\n",
    "    result = \"\"\n",
    "    result+=f\"Generated Code: \\n=======================\\n\"\n",
    "    result+=response.get(\"generated_code\") + \"\\n\\n\"\n",
    "\n",
    "    error = response.get(\"execution_error\")\n",
    "    if len(error) > 1:\n",
    "        result+=f\"Code Execution Error: \\n=======================\\n\"\n",
    "        result+=\"\\\"\" + error + \"\\\"\\n\\n\"                \n",
    "    resultdataframe = pd.DataFrame()   \n",
    "    exe_result = response.get(\"execution_result\")\n",
    "    if len(exe_result) > 1:\n",
    "        StringData = StringIO(exe_result)\n",
    "        resultdataframe = pd.read_csv(StringData, sep =\"\\t\")\n",
    "    \n",
    "    return result,resultdataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MejOedOYxc1O"
   },
   "source": [
    "## Test Code Interpreter\n",
    "\n",
    "To test Code Interpreter, ask it to generate a basic plot from a small dataset.\n",
    "\n",
    "Note that printing the Code Interpreter response object below is a bit long, due to the base64-encoded image file returned by Code Interpreter--just scroll down a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test using Sample Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkgY1Ji-lyWz",
    "outputId": "5883ddb7-83d3-458e-90bd-da7fcddf85ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "Using the data below, construct a bar chart that includes only the height values with different colors for the bars:\n",
    "\n",
    "tree_heights_prices = {\n",
    "  \\\"Pine\\\": {\\\"height\\\": 100, \\\"price\\\": 100},\n",
    "  \\\"Oak\\\": {\\\"height\\\": 65, \\\"price\\\": 135},\n",
    "  \\\"Birch\\\": {\\\"height\\\": 45, \\\"price\\\": 80},\n",
    "  \\\"Redwood\\\": {\\\"height\\\": 200, \\\"price\\\": 200},\n",
    "  \\\"Fir\\\": {\\\"height\\\": 180, \\\"price\\\": 162},\n",
    "}\n",
    "\n",
    "Please include the data in the generated code.\n",
    "\"\"\"\n",
    "\n",
    "response = extension_code_interpreter.execute(\n",
    "    operation_id = \"generate_and_execute\",\n",
    "    operation_params = {\"query\": QUERY},\n",
    ")\n",
    "\n",
    "result,resultdataframe  = format_response(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Code: \n",
      "=======================\n",
      "```python\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the tree heights data\n",
      "tree_heights_prices = {\n",
      "  \"Pine\": {\"height\": 100, \"price\": 100},\n",
      "  \"Oak\": {\"height\": 65, \"price\": 135},\n",
      "  \"Birch\": {\"height\": 45, \"price\": 80},\n",
      "  \"Redwood\": {\"height\": 200, \"price\": 200},\n",
      "  \"Fir\": {\"height\": 180, \"price\": 162},\n",
      "}\n",
      "\n",
      "# Extract height values from the dictionary\n",
      "heights = [tree_data[\"height\"] for tree_data in tree_heights_prices.values()]\n",
      "\n",
      "# Create a bar chart with different colors for each bar\n",
      "plt.bar(tree_heights_prices.keys(), heights, color=[\"red\", \"green\", \"blue\", \"purple\", \"orange\"])\n",
      "\n",
      "# Set chart title and labels\n",
      "plt.title(\"Tree Heights\")\n",
      "plt.xlabel(\"Tree Species\")\n",
      "plt.ylabel(\"Height (ft)\")\n",
      "\n",
      "# Display the chart\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(resultdataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test using Sample CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Files: ['supermarket_sales.csv']\n",
      "Query: From CSV, Can you get me the distinct cities and their max rating where the rating > 9.6\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILES_PATH = [\"/home/jupyter/Extenstion/supermarket_sales.csv\"]\n",
    "FILES = upload_file_multiple(INPUT_FILES_PATH)\n",
    "print(\"Input Files:\", [f[\"name\"] for f in FILES])\n",
    "\n",
    "QUERY = \"From CSV, Can you get me the distinct cities and their max rating where the rating > 9.6\"\n",
    "print(\"Query:\", QUERY)\n",
    "result,resultdataframe  = get_response(QUERY,FILES) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Code: \n",
      "=======================\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV data\n",
      "data = pd.read_csv(\"supermarket_sales.csv\")\n",
      "\n",
      "# Filter the data to only include rows where the rating is greater than 9.6\n",
      "filtered_data = data[data[\"Rating\"] > 9.6]\n",
      "\n",
      "# Get the distinct cities and their maximum rating\n",
      "distinct_cities = filtered_data.groupby(\"City\")[\"Rating\"].max()\n",
      "\n",
      "# Print the results\n",
      "print(distinct_cities)\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEwauD0Xyzru",
    "outputId": "a06dc9f4-ea90-4fa0-fa9e-39b1b0852d56",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           City\n",
      "0             Mandalay     10.0\n",
      "1             Naypyitaw    10.0\n",
      "2             Yangon       10.0\n",
      "3  Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(resultdataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Demo Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 4.22.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://3ca4d5cc70464663dc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3ca4d5cc70464663dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://3ca4d5cc70464663dc.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_like_dislike(x: gr.LikeData):\n",
    "    print(x.index, x.value, x.liked)\n",
    "\n",
    "def add_message(history, message):\n",
    "    for x in message[\"files\"]:\n",
    "        history.append(((x[\"path\"],), None))  \n",
    "    if message[\"text\"] is not None:\n",
    "        history.append((message[\"text\"], None))\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False, file_types=[\"csv\"])\n",
    "\n",
    "\n",
    "def bot(history):\n",
    "    file_name = history[0][0][0]\n",
    "    latest_qn = history[-1][0]\n",
    "    if not file_name:\n",
    "        history[-1][1] = \"\"\n",
    "        \n",
    "    file_text = upload_file(file_name)\n",
    "    answer,resultdataframe = get_response(latest_qn, file_text)\n",
    "    result_text = resultdataframe.to_string(index=False)\n",
    "    # history += [(f\"![]({answer} !{resultdataframe.to_string(index=False)})\", None)]\n",
    "    final_answer = answer + \"Result Set \\n\" + result_text\n",
    "    history[-1][1] = \"\"\n",
    "    history[-1][1] += final_answer\n",
    "    time.sleep(0.05)\n",
    "    yield history\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Talk to CSV\")\n",
    "    chatbot = gr.Chatbot(\n",
    "        [],\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False\n",
    "    )\n",
    "\n",
    "    chat_input = gr.MultimodalTextbox(interactive=True, file_types=[\"csv\"], placeholder=\"Upload your csv file & Ask away!! \", show_label=False)\n",
    "    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input], queue=False).then(\n",
    "        bot, chatbot, chatbot, api_name=\"bot_response\"\n",
    "    )\n",
    "    chat_msg.then(lambda: gr.Textbox(interactive=True), None, [chat_input], queue=False)\n",
    "    chatbot.like(print_like_dislike, None, None)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True,debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9NnhQmFLAHXs",
    "8gZVnoGDbrbT"
   ],
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
